{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMHwrRIOKNmXnrH4rYZYE5S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1jUiLV-B_tzm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719397877491,"user_tz":-540,"elapsed":17403,"user":{"displayName":"성이름","userId":"08756814938595276163"}},"outputId":"41b1f5ca-7829-413c-a731-5ad268d08a97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 2s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 1s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 100)               78500     \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79510 (310.59 KB)\n","Trainable params: 79510 (310.59 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Model: \"패션 MNIST 모델\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hidden (Dense)              (None, 100)               78500     \n","                                                                 \n"," output (Dense)              (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79510 (310.59 KB)\n","Trainable params: 79510 (310.59 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_2 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79510 (310.59 KB)\n","Trainable params: 79510 (310.59 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["from tensorflow import keras\n","(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","\n","from sklearn.model_selection import train_test_split\n","train_scaled = train_input / 255.0\n","train_scaled = train_scaled.reshape(-1,28*28)\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n","\n","# 은닉층과 출력층을 케라스의 Dense 클래스로 만들어보기\n","dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)) # 처음 층을 이룰 때 input_shape를 반드시 써야함\n","dense2 = keras.layers.Dense(10, activation='softmax')\n","# 심층 신경망 만들기\n","model = keras.Sequential([dense1, dense2])\n","model.summary() # output shape = none,100  none,10  param = 78500 1010\n","# batch_size로 미니배치 경사 하강법의 크기를 바꿀 수 있다. 기본값은 32이다.\n","\n","# 층을 추가하는 다른 방법\n","model = keras.Sequential([\n","    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n","    keras.layers.Dense(10, activation='softmax', name='output')\n","], name='패션 MNIST 모델') # name = 이름 지정, activation = 활성화함수 지정\n","model.summary()\n","\n","model = keras.Sequential()\n","model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))) # add()로 추가\n","model.add(keras.layers.Dense(10, activation='softmax'))\n","model.summary()\n","\n","# 컴파일 방식 정하기\n","model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n","model.fit(train_scaled, train_target, epochs=5)\n","\n","# 렐루 함수 : max(0,z) : z>0이면 z를, 음수면 0을 반환한다.\n","model = keras.Sequential()\n","model.add(keras.layers.Flatten(input_shape=(28,28))) # reshape 대신 Flatten으로 평탄화시킬 수도 있다.\n","model.add(keras.layers.Dense(100, activation='relu')) # 렐루 함수 사용\n","model.add(keras.layers.Dense(10, activation='softmax'))\n","model.summary()\n","# Flatten은 모델 파라미터가 0개이다. output shape로 784개의 입력이 전달된다는게 보임. 입력 데이터에 대한 전처리 과정을 가능한 모델에 포함시킨다.\n","\n","(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","train_scaled = train_input / 255.0\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n","\n","model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n","model.fit(train_scaled, train_target, epochs=5)\n","model.evaluate(val_scaled, val_target) # 검증 세트의 성능 확인\n","\n","# 옵티마이저 : 기본 경사 하강법 옵티마이저인 SGD(learning_rate=0.01) -> 모멘텀(momentum>0) -> 네스테로프 모멘텀(nesterov=True) ex) sgd = keras.optimizer.SGD(momentum=0.9, nesterov=True)\n","# 적응적 학습률 옵티마이저인 RMSprop(Learning_rate=0.001) -> Adam 등이 있다.\n","\"\"\"\n","딥러닝 학습시 최대한 틀리지 않는 방향으로 학습해야 한다,\n","얼마나 틀리는지(loss)를 알게 하는 함수가 loss function(손실함수)이다.\n","loss function 의 최솟값을 찾는 것을 학습 목표로 한다.\n","최소값을 찾아가는 것 최적화 = Optimization\n","이를 수행하는 알고리즘이 최적화 알고리즘 = Optimizer 이다.\n","\"\"\"\n","model = keras.Sequential()\n","model.add(keras.layers.Flatten(input_shape=(28,28)))\n","model.add(keras.layers.Dense(100, activation='relu'))\n","model.add(keras.layers.Dense(10, activation='softmax'))\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy') # adam으로 설정해보기\n","model.fit(train_scaled, train_target, epochs=5)\n","\n","model.evaluate(val_scaled, val_target) # 0.87"]}]}