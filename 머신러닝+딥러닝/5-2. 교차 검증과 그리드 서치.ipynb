{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0Aq3R4XvNzaj6bYeB+tkb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-pNmgYycWLI","executionInfo":{"status":"ok","timestamp":1719067468974,"user_tz":-540,"elapsed":39730,"user":{"displayName":"성이름","userId":"08756814938595276163"}},"outputId":"c3e1ad9d-d3fa-426e-c554-ea2defae2b4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4157, 3) (1040, 3)\n","0.9971133028626413\n","0.864423076923077\n","{'fit_time': array([0.0075326 , 0.00788379, 0.00757122, 0.00748992, 0.0072031 ]), 'score_time': array([0.00126696, 0.00145507, 0.00125837, 0.00130653, 0.00121379]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}\n","0.855300214703487\n","0.855300214703487\n","0.8574181117533719\n","0.9615162593804117\n","{'min_impurity_decrease': 0.0001}\n","[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]\n","{'min_impurity_decrease': 0.0001}\n","{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}\n","0.8683865773302731\n","{'max_depth': 45, 'min_impurity_decrease': 0.0004046137691733707, 'min_samples_leaf': 4, 'min_samples_split': 7}\n","0.8699259643147996\n","0.8912834327496633\n","{'max_depth': 28, 'min_impurity_decrease': 0.0002759252526773454, 'min_samples_leaf': 6, 'min_samples_split': 4}\n","0.8493357148145406\n","0.8701173754088898\n"]}],"source":["# 결정 트리, 확률적 경사 하강법은 테스트 세트를 반복해 사용하면서 체크를 한다.\n","# 그렇게 하다보면, 점점 성능을 테스트 세트에 맞춰서 과대적합이 되어버린다. 따라서 훈련,검증,테스트를 각각 60,20,20으로 나누어 진짜 판단할 때에만 검증 케이스를 사용하면 된다.\n","import pandas as pd\n","wine = pd.read_csv('https://bit.ly/wine_csv_data')\n","\n","data = wine[['alcohol','sugar','pH']].to_numpy()\n","target = wine['class'].to_numpy()\n","\n","from sklearn.model_selection import train_test_split\n","train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)  # 훈련 80%, 테스트 20%\n","sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42) # 훈련 80% 중 20%를 때어 약20%(16%이긴 함)을 검증 케이스로 사용한다.\n","\n","print(sub_input.shape, val_input.shape) # (4157, 3) (1040, 3)\n","\n","from sklearn.tree import DecisionTreeClassifier\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(sub_input, sub_target)\n","print(dt.score(sub_input, sub_target)) # 0.99\n","print(dt.score(val_input, val_target)) # 0.86 훈련 세트에 과대적합 되어있음\n","\n","# 교차검증 3,5,10-폴드 교차 검증 : 각각의 횟수만큼 훈련 케이스를 나눈 다음 각각의 일부분을 검증 케이스로 사용하고 평가해서 평균을 낸다. cross_validate(모델 객체, 훈련세트,훈련타깃) : 교차 검증 함수\n","from sklearn.model_selection import cross_validate\n","scores = cross_validate(dt, train_input, train_target) # 기본이 5-폴드 교차검증을 수행한다.\n","# fit time, score time, test score 딕셔너리를 반환한다. (훈련하는 시간, 검증하는 시간,테스트 점수)\n","print(scores)\n","\n","import numpy as np\n","print(np.mean(scores['test_score'])) # 0.8553 scores의 test_score 열에 해당하는 내용 5개의 평균\n","\n","from sklearn.model_selection import StratifiedKFold # 회귀모델 = KFold, 분류 모델 = StratifiedKFold 사용\n","scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())\n","print(np.mean(scores['test_score'])) # 0.855\n","\n","# n_splits = 10으로 10-폴드 교차검증 수행 가능\n","splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","scores = cross_validate(dt,train_input,train_target,cv=splitter)\n","print(np.mean(scores['test_score'])) # 0.857\n","\n","# 하이퍼 파라미터 튜닝(max_depth,min_impurity_decrease 같은 매개변수 중 뭐가 가장 높은 점수를 받는지 여러 경우의 수로 돌리는 것이다.)\n","from sklearn.model_selection import GridSearchCV\n","params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]} # 1. 여러번 수행할 각각의 파라미터를 모아 배열 만들기\n","gs = GridSearchCV(DecisionTreeClassifier(random_state=42),params,n_jobs=-1) # 2. GridSearchCV()로 (cv매개변수는 기본 5) 5x5개의 모델을 훈련 시키도록 gs에 전달\n","gs.fit(train_input,train_target) # 3. 훈련 세트 가져와서 훈련 시키기\n","\n","dt = gs.best_estimator_ # best_estimator_ = 최적의 값을 적용한 모델\n","print(dt.score(train_input,train_target)) # 0.96 그러한 dt의 훈련점수\n","print(gs.best_params_) # {'min_impurity_decrease': 0.0001} 0.0001이 가장 좋은 값으로 선택됨.\n","\n","print(gs.cv_results_['mean_test_score']) # [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605] cv_results에 수행한 후의 결과가 나와있음. mean_test_score은 그 중에서 평균을 구해 놓은거임.\n","best_index = np.argmax(gs.cv_results_['mean_test_score']) # argmax() = 가장 큰 값의 인덱스 선택한다.\n","print(gs.cv_results_['params'][best_index]) # {'min_impurity_decrease': 0.0001}\n","\n","# 여러개의 매개변수 중에서 가장 높은 점수 구하기\n","params = {'min_impurity_decrease':np.arange(0.0001,0.001,0.0001), # 어디까지는 불순도가 감소해야 끝남.\n","          'max_depth': range(5,20,1), # 최대 트리 자식 노드 개수\n","          'min_samples_split': range(2,100,10) # 노드를 나누기 위한 최소 샘플 수\n","          } # 1. 여러번 수행할 각각의 파라미터를 모아 배열 만들기\n","gs = GridSearchCV(DecisionTreeClassifier(random_state=42),params,n_jobs=-1) # 2. GridSearchCV()로 (cv매개변수는 기본 5) 9x15x10 x 5 = 6750번 실행해서 최댓값을 찾는다.\n","gs.fit(train_input,train_target) # 3. 훈련 세트 가져와서 훈련 시키면서 최대인 값 구하기\n","print(gs.best_params_) # {'min_impurity_decrease': 0.0004, 'max_depth': 14, 'min_samples_split': 12}\n","print(np.max(gs.cv_results_['mean_test_score']))\n","\n","# 랜덤 서치 : 값의 범위나 간격을 미리 정하기 어려울 때도 있고 너무 많은 매개변수 조건 때문에 수행 시간이 오래걸릴 수 있으므로 랜덤하게 골라서 쓴다.\n","from scipy.stats import uniform,randint\n","rgen = randint(0,10) # 0~10 정수 범위 설정\n","rgen.rvs(10) # 10개의 정수를 배열로 뽑기\n","np.unique(rgen.rvs(1000),return_counts=True) # 1000개 뽑기(중복된 값이 없도록 unique를 쓴다.) return_counts는 중복된 수가 몇번 반복됐는지 배열로 알려준다.\n","ugen = uniform(0,1) # 0~1 실수 범위 설정\n","ugen.rvs(10) # 10개의 실수를 배열로 뽑기\n","\n","params = {'min_impurity_decrease':uniform(0.0001,0.001), # 어디까지는 불순도가 감소해야 끝남.\n","          'max_depth': randint(20,50), # 최대 트리 자식 노드 개수\n","          'min_samples_split': randint(4,20), # 노드를 나누기 위한 최소 샘플\n","          'min_samples_leaf': randint(3,20) # 리프 노드가 되기 위한 최소 샘플 수\n","          }\n","from sklearn.model_selection import RandomizedSearchCV\n","gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42),params,n_iter=100,n_jobs=-1,random_state=42) # n_iter=100(100번 반복), n_jobs=-1(모든 cpu 사용)\n","gs.fit(train_input,train_target)\n","print(gs.best_params_)\n","print(np.max(gs.cv_results_['mean_test_score']))\n","dt = gs.best_estimator_ # 최적의 값을 적용한 모델\n","print(dt.score(train_input,train_target))\n","\n","# 문제 3. splitter 매개변수는 기본적으로 best로 각 노드에서 최선의 분할을 찾는다. random이면 무작위로 분할한 뒤 가장 좋은 것을 고른다.\n","gs = RandomizedSearchCV(DecisionTreeClassifier(splitter='random',random_state=42),params,n_iter=100,n_jobs=-1,random_state=42) # n_iter=100(100번 반복), n_jobs=-1(모든 cpu 사용)\n","gs.fit(train_input,train_target)\n","print(gs.best_params_)\n","print(np.max(gs.cv_results_['mean_test_score']))\n","dt = gs.best_estimator_ # 최적의 값을 적용한 모델\n","print(dt.score(train_input,train_target))"]}]}